{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_Skimlit_NLP_Milestone_Project_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVFHGvMwF+wl9tX+hJE46C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imran9891/TensorFlow/blob/main/09_Skimlit_NLP_Milestone_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyXfs9lfmFvr"
      },
      "source": [
        "# Milestone Project 2: Skimlit\n",
        "\n",
        "The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
        "\n",
        "The paper we're replicating (the source of the dataset that we'll be using) is available here: https://arxiv.org/abs/1710.06071\n",
        "\n",
        "And reading through the paper above, we see that the model architecture that they use to achieve their best results is availabel here: https://arxiv.org/abs/1612.05251\n",
        "\n",
        "**Resource:** If we want to find the ground truth for this notebook (with lots of diagrams and text annotations) see the Github: https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/09_SkimLit_nlp_milestone_project_2.ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXtTHOIencVx"
      },
      "source": [
        "## Confirm access to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3gIn48uz3NT",
        "outputId": "6a44944c-5991-43bd-c5f4-c27a7c6252b4"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-c1b66ec1-fb7e-7470-dcec-83f2258d17e6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX1VjLhJz-6-"
      },
      "source": [
        "## Getting the data\n",
        "\n",
        "Since we'll be replicating the paper above (PubMed 200k RCT), let's download the dataset they used.\n",
        "\n",
        "We can do so from the authords Github: https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrCXXrEP040N",
        "outputId": "0c4f8743-bb3c-4f3e-a971-372d1ec7a6e9"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIEpDnTrMzat",
        "outputId": "2f0ef32d-8b82-4e1d-877f-29e4f5a1fdd3"
      },
      "source": [
        "!ls pubmed-rct"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAL7jStZ2xi2",
        "outputId": "cffc7687-3ca4-4f4f-e607-3418f332f6a5"
      },
      "source": [
        "# Check what files are in the PubMed_20K dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5SXEy0g7BOF"
      },
      "source": [
        "## Becoming one with the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_0q4s5V3jyI"
      },
      "source": [
        "# Start our experiments using the 20k dataset with numbers replaced by the '@' sign\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opDIdmpK5gca",
        "outputId": "893df557-dd84-44fc-d931-9f23ef9dd151"
      },
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txB9jaNA6EC6"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "Now we've got some text data, it's time to become one with it.\n",
        "\n",
        "So, with that in mind, let's write a function to read in all of the lines of a target text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcx5YMT87__6"
      },
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text filename) and returns the lines of text as a list.\n",
        "\n",
        "  Args:\n",
        "    filename: a string containing the target filepath.\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filenames.\n",
        "  \"\"\"\n",
        "  with open(filename, mode=\"r\") as f:\n",
        "    return f.readlines()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3gPbqUa85-E",
        "outputId": "72807963-3bfd-4df1-9256-847bdd73701a"
      },
      "source": [
        "# Let's read in the training lines\n",
        "train_lines= get_lines(filenames[0]) # read the lines within the training file\n",
        "train_lines[:27]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n',\n",
              " 'METHODS\\tAttentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .\\n',\n",
              " 'METHODS\\tSelf-reported emotional eating was assessed with the Dutch Eating Behavior Questionnaire ( DEBQ ) and ad libitum food intake was tested by a disguised food offer .\\n',\n",
              " 'RESULTS\\tHierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .\\n',\n",
              " 'RESULTS\\tYet , attention maintenance on food cues was significantly related to increased intake specifically in the neutral condition , but not in the sad mood condition .\\n',\n",
              " 'CONCLUSIONS\\tThe current findings show that self-reported emotional eating ( based on the DEBQ ) might not validly predict who overeats when sad , at least not in a laboratory setting with healthy women .\\n',\n",
              " 'CONCLUSIONS\\tResults further suggest that attention maintenance on food relates to eating motivation when in a neutral affective state , and might therefore be a cognitive mechanism contributing to increased food intake in general , but maybe not during sad mood .\\n',\n",
              " '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7ALuD0h9Go5",
        "outputId": "52103eda-e7e0-4971-b698-c34789266e06"
      },
      "source": [
        "len(train_lines)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyuUGRuu9648"
      },
      "source": [
        "# Let's think about how we want our data to look...\n",
        "\n",
        "How I think our data would be best represented...\n",
        "\n",
        "```\n",
        "[{'line_number':0,\n",
        "   'target': 'BACKGROUND',\n",
        "   'text': \"Emotional eating is associated with overeating and the development of obesity .\\n\",\n",
        "   'total_lines': 11},\n",
        "   ...]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJnmjd6--KNL"
      },
      "source": [
        "# Creating a function to convert text into dictionaries\n",
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Args:\n",
        "    filename: Takes in filename, reads it contents and sorts through each line,\n",
        "    extracting things like the target label, the text of the sentence, how many\n",
        "    sentences are in the current abstract and what sentence number the target\n",
        "    line is.\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "\n",
        "  # Loop through each line in the target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if the line is an ID line\n",
        "      abstract_id = line \n",
        "      abstract_lines = \"\" # reset the abstract string if the line is an ID line\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "    \n",
        "      # Iterate through each line in a single abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create an empty dictionary for each line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line apper in the abstract\n",
        "        line_data[\"total line\"] = len(abstract_line_split)-1 # how many total lines are there in the target abstract?  (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyQdY3PGNbbZ",
        "outputId": "13d3dc56-7b9f-4436-abc2-344c3038b491"
      },
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(filenames[0])\n",
        "val_samples = preprocess_text_with_line_numbers(filenames[1])\n",
        "test_samples = preprocess_text_with_line_numbers(filenames[2])\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 551 ms, sys: 117 ms, total: 668 ms\n",
            "Wall time: 667 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY2pW5_4iw6M",
        "outputId": "6b29619f-e4c1-4d71-d834-1ebac28cf27d"
      },
      "source": [
        "# Check the first abstract of the training data\n",
        "train_samples[:20]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total line': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total line': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total line': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total line': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total line': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total line': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total line': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total line': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total line': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total line': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'total line': 11},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total line': 11},\n",
              " {'line_number': 0,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'total line': 10},\n",
              " {'line_number': 1,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'total line': 10},\n",
              " {'line_number': 2,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
              "  'total line': 10},\n",
              " {'line_number': 3,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'it was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .',\n",
              "  'total line': 10},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'participants ( n = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .',\n",
              "  'total line': 10},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'attentional biases for high caloric foods were measured by eye tracking during a visual probe task with pictorial food and neutral stimuli .',\n",
              "  'total line': 10},\n",
              " {'line_number': 6,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'self-reported emotional eating was assessed with the dutch eating behavior questionnaire ( debq ) and ad libitum food intake was tested by a disguised food offer .',\n",
              "  'total line': 10},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'hierarchical multivariate regression modeling showed that self-reported emotional eating did not account for changes in attention allocation for food or food intake in either condition .',\n",
              "  'total line': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ru0kWD-oz9MQ"
      },
      "source": [
        "Now that our data is in the format of a list of dictionaries, how about we turn it into a DataFrame to further visualize it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZu2FisEQvJq"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "j5la0wcFRDiH",
        "outputId": "e23ede3a-45da-447e-d9e8-831ea5c6807e"
      },
      "source": [
        "train_df.head(15)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total line</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>the aim of this study was to test if attention...</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         target  ... total line\n",
              "0     OBJECTIVE  ...         11\n",
              "1       METHODS  ...         11\n",
              "2       METHODS  ...         11\n",
              "3       METHODS  ...         11\n",
              "4       METHODS  ...         11\n",
              "5       METHODS  ...         11\n",
              "6       RESULTS  ...         11\n",
              "7       RESULTS  ...         11\n",
              "8       RESULTS  ...         11\n",
              "9       RESULTS  ...         11\n",
              "10      RESULTS  ...         11\n",
              "11  CONCLUSIONS  ...         11\n",
              "12   BACKGROUND  ...         10\n",
              "13   BACKGROUND  ...         10\n",
              "14    OBJECTIVE  ...         10\n",
              "\n",
              "[15 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk8fZzq_RIxm",
        "outputId": "95e9574b-650e-47f8-a09a-1dfc7492234e"
      },
      "source": [
        "# Check the distribution of labels\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "QJxbOWDjRz-0",
        "outputId": "aa691395-2f76-4007-e470-1f1f2e1f7ac1"
      },
      "source": [
        "# Check the length of different lines\n",
        "train_df[\"total line\"].plot.hist();"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXuEnat6R55r"
      },
      "source": [
        "## Get list of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YxQhOdhTFpS",
        "outputId": "7d5c5383-2dc6-4cbb-b2ca-8def669b1bc0"
      },
      "source": [
        "# Getting a list of sentences from Dataframes\n",
        "train_sentences = train_df[\"text\"].to_list()\n",
        "val_sentences = val_df[\"text\"].to_list()\n",
        "test_sentences = test_df[\"text\"].to_list()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE48Pt23Wy2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eecf27b-a194-4c37-974c-5da6609f28c4"
      },
      "source": [
        "# View the 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xloILkSjSKDd"
      },
      "source": [
        "## Make numeric labels (ML models require numeric labels)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gK6rc9dSxEc",
        "outputId": "114d540d-9ce5-4770-fa97-bd6d8e8105bb"
      },
      "source": [
        "# One hot encode labels for using Categorical Cross Entropy\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(X=train_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(X=val_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(X=test_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "\n",
        "# Check what one hot encoded label look like\n",
        "train_labels_one_hot"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkrTRu3rqYfc",
        "outputId": "2a2b6095-32a9-4bc8-b0c9-377f59a41fb3"
      },
      "source": [
        "train_df[\"target\"].to_numpy()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['OBJECTIVE', 'METHODS', 'METHODS', ..., 'RESULTS', 'CONCLUSIONS',\n",
              "       'CONCLUSIONS'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peR35qw3A1XJ",
        "outputId": "b06d28a2-e06b-4cb8-9f29-2c51c9e20ac6"
      },
      "source": [
        "train_df[\"target\"].to_numpy().reshape(-1,1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['OBJECTIVE'],\n",
              "       ['METHODS'],\n",
              "       ['METHODS'],\n",
              "       ...,\n",
              "       ['RESULTS'],\n",
              "       ['CONCLUSIONS'],\n",
              "       ['CONCLUSIONS']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hozp2cCXMA1"
      },
      "source": [
        "## Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLGR0XQMVor7",
        "outputId": "a3c49010-b47d-4d3e-8be3-3a264112427f"
      },
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWJ4JkbGXSbn",
        "outputId": "7d841ff4-4a9e-4663-89b1-1a7a000f36fd"
      },
      "source": [
        "# Get class names and number of classes from label encoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btNOJsprBSzw",
        "outputId": "b9edeb7d-7360-4183-f6ce-5c9db1bb3059"
      },
      "source": [
        "# Get class names and number of classes from one hot encoder instance\n",
        "nc = len(one_hot_encoder.categories_[0])\n",
        "cn = one_hot_encoder.categories_\n",
        "nc,cn"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, [array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "        dtype=object)])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gG4yOdH3ByRV",
        "outputId": "622f0e87-ba36-4df7-99bc-d502aaace851"
      },
      "source": [
        "class_names == cn"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True,  True,  True,  True,  True]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slhL_4P-Yvg9"
      },
      "source": [
        "## Starting a series of modelling experiments\n",
        "\n",
        "As usual, we're going to be trying out a bunch of different models and seeing which one works best. And as always, we're going to start with a baseline (TF_IDF Multinomial Naive Bayes Classifier)\n",
        "\n",
        "1. Model_0: Naive Bayes with TF-IDF encoder (baseline)\n",
        "2. Model_1: Conv1D with token embeddings\n",
        "3. Model_2: TensorFlow Hub Pretrained Feature Extractor\n",
        "4. Model_3: Conv_1D with character embeddings\n",
        "5. Model_4: Pretrained token embeddings (same as 2) + character embeddings (same as 3)\n",
        "6. Model_5: Pretrained token embeddings + character embeddings + positional embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6VNub2MdJEs"
      },
      "source": [
        "## Model 0: Baseline model (Term Frequency  Inverse Document Frequency)\n",
        "\n",
        "For more knowledge on TF-IDF see: https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSY6Gus7dLVO",
        "outputId": "5a5bb26d-805d-4cf9-d33c-9bc30f799e78"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\",TfidfVectorizer()),\n",
        "    (\"clf\",MultinomialNB())\n",
        "])\n",
        "model_0.fit(train_sentences,\n",
        "            train_labels_encoded)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP0vG_lsePTq",
        "outputId": "944f3005-c1b5-4661-cff8-ba16e73092b4"
      },
      "source": [
        "model_0.score(val_sentences, val_labels_encoded)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC_3_2fyix4m",
        "outputId": "b123e0a8-af31-4f5f-f63d-cde6c877adf1"
      },
      "source": [
        "# Make predictions with the baseline model\n",
        "model_0_preds = model_0.predict(val_sentences)\n",
        "model_0_preds"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFR91tp7i_Tc",
        "outputId": "c462d1c0-ae6a-4c71-9c0f-52fa6753da51"
      },
      "source": [
        "# Check val labels\n",
        "val_labels_encoded"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGuSlTv3fCem"
      },
      "source": [
        "# Make predictions and return results using our baseline model\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true,y_pred):\n",
        "  results = {}\n",
        "  acc_score = accuracy_score(y_true,y_pred)\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true,y_pred,average=\"weighted\")\n",
        "  results[\"accuracy\"] = acc_score*100\n",
        "  results[\"precision\"] = model_precision\n",
        "  results[\"recall\"] = model_recall\n",
        "  results[\"f1-score\"] = model_f1\n",
        "  return results"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4adNkkuIfHfw",
        "outputId": "e5ca7a34-c91a-4326-de9e-a1d7e69c8bd7"
      },
      "source": [
        "# Check baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=model_0_preds)\n",
        "baseline_results"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1-score': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwkeUqij03cs"
      },
      "source": [
        "## Preparing our data (the text) for deep sequence models\n",
        "\n",
        "Before we start building deeper models, we've got to create vectorization and embedding layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1-OaliqmZqm"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOSgWlCLv61U",
        "outputId": "8be95029-1f52-40a4-cf51-d9057d375562"
      },
      "source": [
        "# How long is each sentence on an average?\n",
        "import numpy as np\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences] # counts each word in separate lines\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vOFcYhdM124h",
        "outputId": "6d458bca-52c5-4c1a-91c7-2f7430994b9c"
      },
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens,bins=20);"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1gwCYwz2qiO",
        "outputId": "32ddfba9-5c24-4a29-a67b-5996e621b9f2"
      },
      "source": [
        "# How long of a sentence length covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens,95))\n",
        "output_seq_len # around 95% of the sentences are under 55 tokens in length"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LpFA_gI3tSK",
        "outputId": "70b1010a-dd7c-4489-aae3-480807513ae4"
      },
      "source": [
        "# Maximum sequence length in the training set\n",
        "max(sent_lens)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHx0mI2V6NtB"
      },
      "source": [
        "### Create text vectorizer layer\n",
        "\n",
        "We want to make a layer which maps our texts from words to numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLxjPiOqvau2"
      },
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "max_vocab_length = 68000 # taken from paper\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_sequence_length=output_seq_len,\n",
        "                                    pad_to_max_tokens=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaP-ihJfvnZZ"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugGh57S5yktT",
        "outputId": "18e8d96a-bf03-437c-e981-36d0ec05d05b"
      },
      "source": [
        "# Test out text vectorizer on random sentences\n",
        "import random\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{random_sentence}\\n\\nLength of text: {len(random_sentence.split())} \\n\\nText Vectorizer output:\\n {text_vectorizer([random_sentence])}\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "genentech .\n",
            "\n",
            "Length of text: 2 \n",
            "\n",
            "Text Vectorizer output:\n",
            " [[12644     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s8thpnk-V55",
        "outputId": "0a8eb7ec-c0ab-4980-f664-7a494f3da7f0"
      },
      "source": [
        "# How many words in vocabulary, most common words, most least common words?\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Total words in vocabulary: {len(words_in_vocab)}\\n10 Most common words: {words_in_vocab[:10]}\\n10 Most Least Common Words: {words_in_vocab[-10:]}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words in vocabulary: 64841\n",
            "10 Most common words: ['', '[UNK]', 'the', 'and', 'of', 'in', 'to', 'with', 'a', 'were']\n",
            "10 Most Least Common Words: ['aarm', 'aaqol', 'aaq', 'aanhui', 'aana', 'aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9u9dn1I_tca",
        "outputId": "9d2f5eea-678d-4949-fdbd-56c9e8783ad8"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': True,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1uH10MYBBVL"
      },
      "source": [
        "### Create custom text embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8h7g210zQod"
      },
      "source": [
        "# Create token embedding layer (feature-vector matrix representation)\n",
        "from tensorflow.keras import layers\n",
        "token_embed = layers.Embedding(input_dim=max_vocab_length, # length of vocabulary\n",
        "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               mask_zero=True, # use masking to handle variable sequence length (save space)\n",
        "                               input_length=output_seq_len,\n",
        "                               name=\"token_embedding\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlNW---MzoBi",
        "outputId": "c23d1c79-5188-4497-d20d-cdf1c1ffa4ff"
      },
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n {random_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([random_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n {vectorized_sentence}\\n\")\n",
        "embedding_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n {embedding_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedding_sentence.shape}\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            " genentech .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            " [[12644     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "\n",
            "Sentence after embedding:\n",
            " [[[-0.03463376 -0.01620088 -0.02343217 ... -0.01531476 -0.03951259\n",
            "   -0.01163956]\n",
            "  [-0.02700077  0.02049545 -0.01646866 ...  0.02615025 -0.02743224\n",
            "    0.01419636]\n",
            "  [-0.02700077  0.02049545 -0.01646866 ...  0.02615025 -0.02743224\n",
            "    0.01419636]\n",
            "  ...\n",
            "  [-0.02700077  0.02049545 -0.01646866 ...  0.02615025 -0.02743224\n",
            "    0.01419636]\n",
            "  [-0.02700077  0.02049545 -0.01646866 ...  0.02615025 -0.02743224\n",
            "    0.01419636]\n",
            "  [-0.02700077  0.02049545 -0.01646866 ...  0.02615025 -0.02743224\n",
            "    0.01419636]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k6th-l60SZr"
      },
      "source": [
        "## Creating datasets (making sure our data loads as fast as possible)\n",
        "\n",
        "We're going to setup our data to run as fast as possible with the TensorFlow tf.data API, many of the steps here are discusses at length in these two resources:\n",
        "* https://www.tensorflow.org/guide/data_performance\n",
        "* https://www.tensorflow.org/guide/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rolLiM0Ft78",
        "outputId": "c2b7f00e-3170-4939-f495-19758a21675d"
      },
      "source": [
        "# Turn our data into TensorFlow datasets (passing one_hot_encoded labels)\n",
        "import tensorflow as tf\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences,train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTCKeJ4tHipc",
        "outputId": "628e5b15-0369-449e-c068-6722cc51f9b7"
      },
      "source": [
        "# Take the TensorSlice Datasets and turn them into prefetched datasets\n",
        "train_dataset = train_dataset.batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2dT_ja-JFLe"
      },
      "source": [
        "## Model_1: Conv1D with token embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zuvURtgJO_C"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,),dtype=tf.string,name='input_layer')\n",
        "x = text_vectorizer(inputs)\n",
        "x = token_embed(x)\n",
        "x = layers.Conv1D(filters=64,\n",
        "                  kernel_size=5,\n",
        "                  strides=1,\n",
        "                  padding=\"same\",\n",
        "                  activation=\"relu\") (x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(5, activation=\"softmax\",name=\"output_layer\")(x)\n",
        "model_1 = tf.keras.Model(inputs,outputs,name='Conv1D')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4fSQ5reK3uW",
        "outputId": "92db445f-ce8f-44b2-cd8d-6d748de12d47"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 55)                0         \n",
            "_________________________________________________________________\n",
            "token_embedding (Embedding)  (None, 55, 128)           8704000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 55, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 8,745,349\n",
            "Trainable params: 8,745,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbSio3K7NQB2"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(\n",
        "    loss = \"categorical_crossentropy\",\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXWLHP1eNnAR",
        "outputId": "2f7eb28e-3634-4606-8b02-83efcdacc0d7"
      },
      "source": [
        "# Fit the model\n",
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(len(train_dataset)*0.1),\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(len(valid_dataset)*0.1))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 37s 14ms/step - loss: 0.9037 - accuracy: 0.6457 - val_loss: 0.6837 - val_accuracy: 0.7357\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.6635 - accuracy: 0.7524 - val_loss: 0.6404 - val_accuracy: 0.7670\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 8s 13ms/step - loss: 0.6258 - accuracy: 0.7681 - val_loss: 0.6019 - val_accuracy: 0.7819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A3Xi4GFO3Fw",
        "outputId": "15567a60-99e3-4e14-dd4f-a68750b6fa1e"
      },
      "source": [
        "# Evaluate on whole valid dataset\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 4s 4ms/step - loss: 0.6058 - accuracy: 0.7821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6058319211006165, 0.7820733189582825]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To-SJzdIO4YF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "414e7d63-67f5-478a-be63-3017ad340097"
      },
      "source": [
        "# Make predictions (our model predicts prediction probabilities for each class)\n",
        "model_1_pred_probs= model_1.predict(valid_dataset)\n",
        "model_1_pred_probs, model_1_pred_probs.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[4.2639786e-01, 1.8657599e-01, 8.1832901e-02, 2.7901563e-01,\n",
              "         2.6177652e-02],\n",
              "        [4.8871705e-01, 2.7216190e-01, 1.2818152e-02, 2.1891277e-01,\n",
              "         7.3902807e-03],\n",
              "        [1.6338412e-01, 6.2021883e-03, 2.8063424e-03, 8.2757509e-01,\n",
              "         3.2235534e-05],\n",
              "        ...,\n",
              "        [3.6979113e-06, 1.0558027e-03, 9.8011130e-04, 3.4085249e-06,\n",
              "         9.9795699e-01],\n",
              "        [4.7001991e-02, 5.1798826e-01, 7.2560735e-02, 5.7974838e-02,\n",
              "         3.0447417e-01],\n",
              "        [1.9951829e-01, 6.2089694e-01, 4.5551155e-02, 5.3284027e-02,\n",
              "         8.0749564e-02]], dtype=float32), (30212, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDRugusLetJy",
        "outputId": "4e03d92e-7d8f-49fe-fc9c-6dcff3a69aa4"
      },
      "source": [
        "# Convert pred probs to classes\n",
        "model_1_preds = model_1_pred_probs.argmax(axis=1)\n",
        "model_1_preds"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZxT44hre3RW",
        "outputId": "70429c8b-c878-4ce3-ba86-94159f0eb0e2"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.20733483384086,\n",
              " 'f1-score': 0.7795966224948089,\n",
              " 'precision': 0.7785678586831211,\n",
              " 'recall': 0.7820733483384086}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7E2LwiEhnvI"
      },
      "source": [
        "## Model 2: Feature Extraction with pretrained token embeddings\n",
        "\n",
        "Now let's use pretrained word embeddings from TensorFlow Hub, more specifically the universal sentence encoder:\n",
        "https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "The paper originally use GloVe embeddings, however, we're going to stick with the later created `USE` pretrained embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRLU2AC0oKh-"
      },
      "source": [
        "### Model_2: USE (Universal Sentence Encoder)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cifhRkn8olGh"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "USE_URL = \"https://tfhub.dev/google/universal-sentence-encoder/4\""
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm5ZDZaBoreQ"
      },
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "hub_embedding_layer = hub.KerasLayer(USE_URL,\n",
        "                                     trainable=False,\n",
        "                                     name=\"universal_sentence_encoder\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6R_Xjb0paBB",
        "outputId": "15166db2-1a49-46e0-a7e0-ed51aa584aa6"
      },
      "source": [
        "# Test out the pretrained embedding on a random sentence\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Random sentence:\\n {random_sentence}\\n\")\n",
        "use_embedding_sentence = hub_embedding_layer([random_sentence])\n",
        "print(f\"Sentence after embedding:\\n {use_embedding_sentence}\\n\")\n",
        "print(f\"Shape of sentence embedding: {use_embedding_sentence.shape}\")"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random sentence:\n",
            " there is a paucity of reports on the effects of lia on functional capability and quality of life .\n",
            "\n",
            "Sentence after embedding:\n",
            " [[ 4.28144671e-02 -1.54402303e-02  2.27830391e-02  1.32070966e-02\n",
            "   6.61118608e-03  3.00450809e-02 -4.26161960e-02  4.00601998e-02\n",
            "  -3.98725783e-03  2.02434547e-02  3.70050669e-02  5.42537682e-02\n",
            "   3.63755561e-02  9.79618803e-02  3.66396010e-02 -5.46394512e-02\n",
            "  -4.79393639e-02  7.20659718e-02  1.46354188e-03  3.38633955e-02\n",
            "   8.37596059e-02 -1.43369669e-02  4.76383679e-02  4.79945317e-02\n",
            "   1.17568243e-02  3.80227715e-02  2.88032973e-03  6.38681650e-02\n",
            "  -4.21610512e-02  5.66460975e-02  5.56122102e-02 -3.57527495e-03\n",
            "  -1.64350644e-02 -6.31153733e-02 -7.08022192e-02 -2.24266760e-02\n",
            "  -6.30831271e-02 -4.26837020e-02 -2.53521628e-03  3.99829671e-02\n",
            "  -5.22715412e-02  4.58564423e-02 -6.43485459e-03  1.08193867e-02\n",
            "   5.66352298e-03 -4.12754752e-02  3.66210900e-02  3.44533543e-03\n",
            "   3.43619846e-02 -2.24897694e-02 -7.81381503e-02 -3.03646605e-02\n",
            "  -2.33077761e-02  2.53507029e-02  5.07082716e-02  2.69837677e-02\n",
            "   1.21053681e-02  2.00529397e-02  4.61660475e-02 -2.65222527e-02\n",
            "  -5.88474497e-02  2.89584454e-02 -5.00484928e-02  2.66346727e-02\n",
            "   4.86177020e-03 -4.15219702e-02  6.74413070e-02  8.46233964e-02\n",
            "   1.58955287e-02 -2.96524037e-02  1.01089897e-02 -1.86770894e-02\n",
            "  -1.44127235e-02 -7.22657666e-02 -3.09448428e-02 -1.78479869e-02\n",
            "  -5.24349175e-02 -2.69530714e-02  4.18212377e-02  3.91302183e-02\n",
            "  -5.75603247e-02 -3.03373467e-02  4.54324447e-02  6.16208352e-02\n",
            "   8.08658265e-03 -4.73640580e-03 -3.85105647e-02  2.32710317e-02\n",
            "  -6.92008575e-03 -1.72941424e-02  5.68644814e-02  7.15162605e-02\n",
            "  -1.38038313e-02  1.40465877e-03 -2.50924174e-02  3.30823585e-02\n",
            "  -9.91245266e-03 -2.14884570e-03  9.46951844e-03  3.22917178e-02\n",
            "  -5.22207431e-02 -4.81272265e-02 -9.56955329e-02  5.95310442e-02\n",
            "  -2.77915653e-02 -4.06969078e-02  3.53651680e-02 -4.20812331e-02\n",
            "   3.29025909e-02 -4.35732305e-02  1.66931860e-02  1.31368740e-02\n",
            "  -6.07434176e-02  3.72406095e-02  6.65637702e-02  3.40365432e-02\n",
            "  -8.44538733e-02 -1.53928914e-03 -7.00799525e-02 -6.56630024e-02\n",
            "   1.02870157e-02  8.68019760e-02  2.22890098e-02 -4.57810313e-02\n",
            "  -3.93613987e-02 -7.56698474e-02 -5.81527092e-02  4.74648513e-02\n",
            "   7.50470832e-02  4.08101231e-02 -8.81301388e-02  6.16274439e-02\n",
            "  -7.36981183e-02  1.73357334e-02  5.33302538e-02 -3.63353118e-02\n",
            "   4.63028699e-02  4.15720008e-02  1.83243118e-02  3.77584901e-03\n",
            "   8.40299856e-03 -9.50104650e-03  5.34800254e-02 -3.76666966e-03\n",
            "   8.05900395e-02  1.60147473e-02  2.18972517e-03  2.78490949e-02\n",
            "   6.83530122e-02 -7.99481943e-03 -3.61744575e-02 -5.05042411e-02\n",
            "  -4.93393429e-02 -1.27609819e-02  2.52310615e-02  4.99695614e-02\n",
            "   4.11099270e-02 -5.74207352e-03 -2.59620380e-02  5.04336916e-02\n",
            "  -5.11579737e-02  7.35487277e-03  7.21489564e-02 -3.93296368e-02\n",
            "  -4.57402952e-02  5.16838618e-02 -5.14190197e-02 -7.22636143e-03\n",
            "  -2.52874233e-02 -4.53609824e-02  3.57294492e-02 -7.20281899e-02\n",
            "  -2.73127761e-02 -7.33968690e-02  1.62333325e-02  5.45330346e-02\n",
            "  -1.89326592e-02 -5.94899431e-03  4.57457936e-04  6.72667957e-05\n",
            "  -1.17505929e-02  1.27014322e-02 -4.90654148e-02 -3.67113575e-02\n",
            "   3.78447324e-02  1.95347778e-02 -9.41540580e-03 -4.90325727e-02\n",
            "   6.97685257e-02  3.82697122e-04 -3.59779736e-03  3.44854966e-02\n",
            "   3.90508808e-02  4.93229134e-03  4.78878617e-02 -4.97530177e-02\n",
            "   3.23347785e-02  1.45830614e-02  8.80815089e-02  1.06710782e-02\n",
            "   4.69032563e-02  1.82790738e-02 -3.96342091e-02  1.11525478e-02\n",
            "  -6.49159849e-02  1.87661313e-02  6.91602379e-02  6.46507181e-03\n",
            "   1.33315390e-02 -5.47255855e-03  6.64109588e-02  1.74189638e-02\n",
            "  -2.94765085e-03 -3.05186063e-02  4.22197245e-02  1.14057176e-02\n",
            "  -2.18505971e-02 -5.96275777e-02  3.30595975e-03 -5.65955453e-02\n",
            "   1.53560620e-02  2.29592305e-02 -3.25723365e-02  3.14425230e-02\n",
            "  -2.48696227e-02 -8.40194449e-02 -1.21222921e-02 -8.78575742e-02\n",
            "  -3.32844518e-02  7.41926208e-02 -2.20432505e-03  8.64455104e-02\n",
            "   6.33392995e-03  3.24159674e-02  1.08917495e-02 -3.42200659e-02\n",
            "  -6.05337285e-02 -6.45215763e-03 -5.71774924e-03  3.58525142e-02\n",
            "   3.46487872e-02  4.16058227e-02 -6.10322226e-03 -7.17555434e-02\n",
            "  -4.18185852e-02 -8.25066864e-02  5.61091937e-02 -2.37555243e-02\n",
            "   8.47689062e-02 -1.51669630e-03 -6.62987083e-02  1.10261776e-02\n",
            "  -3.19069065e-02  5.73851354e-02 -9.09195188e-03 -1.99190993e-02\n",
            "   4.57091033e-02  2.51022372e-02  7.70567581e-02  8.37432668e-02\n",
            "   5.54142240e-03 -7.48101668e-03 -9.56419110e-02 -2.36787479e-02\n",
            "  -5.52554876e-02 -4.78890166e-02  3.64732668e-02 -3.34977545e-02\n",
            "   9.49429628e-03 -3.32221650e-02 -7.57025275e-03 -4.11253348e-02\n",
            "  -1.08281942e-03 -3.48208211e-02 -6.84837997e-03 -9.57815070e-03\n",
            "   1.87474024e-02 -4.63998429e-02 -2.90667340e-02 -8.53781328e-02\n",
            "  -7.82573316e-03 -9.02239010e-02  5.53544313e-02  3.25554498e-02\n",
            "   4.00648341e-02 -2.00829189e-02  2.96906736e-02 -7.07630813e-02\n",
            "  -1.76543426e-02 -8.91479198e-04 -4.18966264e-02  8.65717977e-02\n",
            "  -6.17632307e-02 -3.90644297e-02 -1.59726590e-02 -1.07368771e-02\n",
            "  -4.23446670e-02  7.65063912e-02  4.06636335e-02  6.54590502e-02\n",
            "  -8.18418786e-02  2.98724063e-02  2.54990757e-02  6.13793209e-02\n",
            "  -1.85364843e-04  5.69230653e-02 -2.02380996e-02  5.48155569e-02\n",
            "   2.04500798e-02 -3.88894416e-02 -1.32278055e-02 -5.06204143e-02\n",
            "   3.73651460e-02 -2.98739485e-02 -3.32777724e-02  1.15898140e-02\n",
            "  -5.92866279e-02  1.08152004e-02  2.90274471e-02 -9.57167614e-03\n",
            "  -5.42424843e-02 -2.25262921e-02  2.59277448e-02 -4.16253917e-02\n",
            "   4.11272123e-02  7.41909891e-02  4.42953706e-02  5.90127409e-02\n",
            "  -6.77312016e-02 -3.19421515e-02 -7.74332061e-02 -7.75963366e-02\n",
            "  -9.68498737e-03  3.73643748e-02 -1.32033648e-02 -6.12369515e-02\n",
            "   7.11026341e-02  6.04491420e-02  4.71654208e-03 -3.06452811e-02\n",
            "  -8.55510905e-02 -6.39429456e-03 -4.90192771e-02  3.79176363e-02\n",
            "  -3.24485004e-02 -1.93873793e-02 -4.49831486e-02  3.51109877e-02\n",
            "  -3.08331326e-02 -7.99714960e-03 -3.65213081e-02  4.08380330e-02\n",
            "  -9.54241678e-03 -2.01874459e-03  5.39366640e-02 -2.38668472e-02\n",
            "  -1.75871979e-02 -4.35697697e-02  4.35429960e-02  1.80974659e-02\n",
            "  -8.05612747e-03 -9.56796110e-03 -4.52615023e-02  5.34188077e-02\n",
            "  -3.17761973e-02 -1.84393842e-02  2.89265849e-02  3.05406563e-02\n",
            "  -1.96664454e-03  8.27315636e-03 -2.59834379e-02  3.53933126e-02\n",
            "   5.70263378e-02 -5.88709749e-02  3.73110510e-02  1.19156344e-02\n",
            "   2.55645327e-02  2.37846468e-02  2.07896195e-02 -1.20261190e-02\n",
            "  -2.31598448e-02 -2.36061052e-03  8.47545341e-02 -3.83429304e-02\n",
            "  -4.96801585e-02  3.46126668e-02  6.43996373e-02 -4.55213040e-02\n",
            "  -2.79675648e-02 -2.40250286e-02  3.40391695e-02  3.60697396e-02\n",
            "  -3.75513434e-02 -7.66429380e-02  5.25797978e-02 -4.25808281e-02\n",
            "   8.34869891e-02  8.72332528e-02 -7.52115250e-02  3.32385153e-02\n",
            "  -9.35291424e-02 -6.06922582e-02 -3.54345664e-02 -5.72655946e-02\n",
            "  -2.90403292e-02  1.37810111e-02 -9.55406949e-03  7.29388818e-02\n",
            "  -5.42262271e-02  1.75976269e-02 -7.58318231e-02  2.29325574e-02\n",
            "   6.39229938e-02  1.21755374e-03 -2.32437830e-02  1.68721881e-02\n",
            "   4.22624722e-02 -4.91391383e-02 -1.50539614e-02 -5.40526211e-02\n",
            "   2.19752248e-02 -3.71524729e-02 -5.51807992e-02  3.22022960e-02\n",
            "  -2.07718667e-02 -6.35433570e-02  8.54505002e-02  2.48616226e-02\n",
            "  -1.27368197e-02 -6.11073337e-02 -1.63778365e-02  6.12843186e-02\n",
            "   2.10563317e-02  1.88474869e-03 -5.37077375e-02 -7.05950186e-02\n",
            "  -5.20625748e-02  3.52262929e-02 -6.20641783e-02 -4.93422225e-02\n",
            "  -5.75586222e-02  2.63670161e-02 -5.55646084e-02  1.70668811e-02\n",
            "   3.07929572e-02  1.41386688e-02 -1.15334792e-02  1.11321313e-03\n",
            "   5.73111624e-02 -6.88759908e-02 -7.35854208e-02  3.33029591e-02\n",
            "   1.34734008e-02 -3.08661219e-02  5.88030927e-02  7.05881510e-03\n",
            "  -5.25132976e-02 -5.19884266e-02 -2.85368203e-03 -6.15515821e-02\n",
            "  -2.00303979e-02  9.64616090e-02  1.78815648e-02 -1.04883453e-03\n",
            "   1.71621144e-02 -1.23267919e-02 -6.19134642e-02 -2.19005160e-02\n",
            "   4.37874459e-02 -4.19517979e-02 -4.18307148e-02 -8.49577598e-03\n",
            "  -1.99288987e-02  2.09027342e-02 -7.88179263e-02  6.13134867e-03\n",
            "   9.32320878e-02 -3.86830308e-02  4.93940115e-02  6.92170486e-02\n",
            "   3.78763489e-02  5.69830313e-02 -7.22187534e-02  4.78935279e-02\n",
            "  -5.72832720e-03  2.66549885e-02 -7.81441014e-03  7.62576163e-02\n",
            "   3.82730551e-02  3.79447788e-02  3.01276371e-02  2.59718522e-02\n",
            "   3.38630681e-03 -1.21887196e-02  7.61703700e-02  6.24178983e-02\n",
            "  -3.39253284e-02 -4.47071977e-02  4.11584228e-02 -8.77388641e-02\n",
            "  -4.51473258e-02 -1.64429452e-02 -7.50373527e-02  4.66319062e-02\n",
            "  -1.47385597e-02 -2.73669176e-02  1.79185234e-02 -2.79589519e-02\n",
            "   7.36578777e-02 -4.60766628e-02 -5.69644794e-02 -3.68966609e-02]]\n",
            "\n",
            "Shape of sentence embedding: (1, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_tz7XsQvM50"
      },
      "source": [
        "## Building and fitting an NLP feature extraction model using pretrained embeddings from TensorFlow Hub\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyj8TiuvvhA5"
      },
      "source": [
        "inputs = layers.Input(shape=[],dtype=tf.string,name=\"input_layer\")\n",
        "pretrained_embedding = hub_embedding_layer(inputs) # tokenize text and create embedding of each sequence (512 long vector)\n",
        "x = layers.Dense(128,activation=\"relu\")(pretrained_embedding)\n",
        "# Note: we could add more layers if we wanted to\n",
        "outputs = layers.Dense(num_classes,activation=\"softmax\")(x)\n",
        "model_2 = tf.keras.Model(inputs,outputs,name=\"model_2_USE_feature_extractor\")\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvY12dVKw1TG",
        "outputId": "3e31271f-f75d-4522-eacc-cfe3638d7cd6"
      },
      "source": [
        "# Get the summary\n",
        "model_2.summary()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_USE_feature_extractor\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None,)]                 0         \n",
            "_________________________________________________________________\n",
            "universal_sentence_encoder ( (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               65664     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ3sJ0ckstv8",
        "outputId": "cb9610b4-dfd2-451f-a9a1-48ee9a18b7e3"
      },
      "source": [
        "# Fit the model\n",
        "history_model_2 = model_2.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset)))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 13s 18ms/step - loss: 0.9152 - accuracy: 0.6519 - val_loss: 0.7953 - val_accuracy: 0.6898\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 10s 18ms/step - loss: 0.7684 - accuracy: 0.7030 - val_loss: 0.7531 - val_accuracy: 0.7064\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 10s 17ms/step - loss: 0.7522 - accuracy: 0.7132 - val_loss: 0.7379 - val_accuracy: 0.7108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RokndGSqxklc",
        "outputId": "7e7c50ce-329e-40eb-f13c-7069f188f506"
      },
      "source": [
        "# Evaluate on the whole dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 14s 15ms/step - loss: 0.7411 - accuracy: 0.7136\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7411132454872131, 0.7135906219482422]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HohAOtgZx2Iw",
        "outputId": "b43f7406-8018-4dbb-c7e8-95a87067ae62"
      },
      "source": [
        "# Make predictions\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs, model_2_pred_probs.shape"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[4.1147950e-01, 3.6516097e-01, 2.8535966e-03, 2.1151282e-01,\n",
              "         8.9931600e-03],\n",
              "        [3.4751484e-01, 4.9235365e-01, 2.9398208e-03, 1.5411229e-01,\n",
              "         3.0794370e-03],\n",
              "        [2.1890311e-01, 1.2803510e-01, 1.7173560e-02, 5.9545064e-01,\n",
              "         4.0437616e-02],\n",
              "        ...,\n",
              "        [1.8260496e-03, 6.0548829e-03, 5.8133926e-02, 8.4660202e-04,\n",
              "         9.3313861e-01],\n",
              "        [3.5808873e-03, 4.8112188e-02, 1.9788779e-01, 1.3947099e-03,\n",
              "         7.4902445e-01],\n",
              "        [1.6610600e-01, 2.7047777e-01, 4.9670374e-01, 5.1587061e-03,\n",
              "         6.1553776e-02]], dtype=float32), (30212, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KD8BjUqhyGhR",
        "outputId": "138bdfac-cb7a-41ea-e20d-8f16898d8bf2"
      },
      "source": [
        "# Convert pred_probs to classes\n",
        "model_2_preds = model_2_pred_probs.argmax(axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 3, ..., 4, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8RjKhVAyYQ6",
        "outputId": "5ec74ab6-a2a4-42af-f1c7-5120834694a5"
      },
      "source": [
        "# Getting the model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.35906262412286,\n",
              " 'f1-score': 0.7105437576408768,\n",
              " 'precision': 0.7137814678309403,\n",
              " 'recall': 0.7135906262412286}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHAyQr5MynEU"
      },
      "source": [
        "## Model 3: Conv1D with character embeddings\n",
        "\n",
        "The paper which we're replicating states they used a combination of token and character-level embeddings.\n",
        "\n",
        "Previosuly, we've token-level embeddings but we'll need to do similar steps for characters if we want to use char-level embeddings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEOwbN2VGSaX"
      },
      "source": [
        "### Creating a character level tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oXqqgn7GWHD",
        "outputId": "628b93fa-308a-4985-e123-9611401e2a8a"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ViD4xx3nQSjk",
        "outputId": "e59a62ea-f7c0-4f68-ee0c-78f3151fb890"
      },
      "source": [
        "\" \".join(list(train_sentences[0]))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .'"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJMeOBxWGZCI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fee10afe-ce0e-4d63-a110-30dd94273a4c"
      },
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Text splitting non-character-level sequence into characters\n",
        "split_chars(random_sentence)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'t h e r e   i s   a   p a u c i t y   o f   r e p o r t s   o n   t h e   e f f e c t s   o f   l i a   o n   f u n c t i o n a l   c a p a b i l i t y   a n d   q u a l i t y   o f   l i f e   .'"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgSjBOGpL3Pl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d01285-d568-4b5a-bf4e-003dc95bf8f0"
      },
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "train_chars[:5]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .',\n",
              " 'a   t o t a l   o f   @   p a t i e n t s   w i t h   p r i m a r y   k n e e   o a   w e r e   r a n d o m i z e d   @ : @   ;   @   r e c e i v e d   @   m g / d a y   o f   p r e d n i s o l o n e   a n d   @   r e c e i v e d   p l a c e b o   f o r   @   w e e k s   .',\n",
              " 'o u t c o m e   m e a s u r e s   i n c l u d e d   p a i n   r e d u c t i o n   a n d   i m p r o v e m e n t   i n   f u n c t i o n   s c o r e s   a n d   s y s t e m i c   i n f l a m m a t i o n   m a r k e r s   .',\n",
              " 'p a i n   w a s   a s s e s s e d   u s i n g   t h e   v i s u a l   a n a l o g   p a i n   s c a l e   (   @ - @   m m   )   .',\n",
              " 's e c o n d a r y   o u t c o m e   m e a s u r e s   i n c l u d e d   t h e   w e s t e r n   o n t a r i o   a n d   m c m a s t e r   u n i v e r s i t i e s   o s t e o a r t h r i t i s   i n d e x   s c o r e s   ,   p a t i e n t   g l o b a l   a s s e s s m e n t   (   p g a   )   o f   t h e   s e v e r i t y   o f   k n e e   o a   ,   a n d   @ - m i n   w a l k   d i s t a n c e   (   @ m w d   )   .']"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w42pBNSiSHkI",
        "outputId": "37c8f35a-2e56-42ac-b6af-cca4e303bbee"
      },
      "source": [
        "# What's the average character length?\n",
        "char_length = [len(sentence) for sentence in train_sentences] # counts lenght of all characters in a single sequence\n",
        "avg_char_length = np.mean(char_length)\n",
        "avg_char_length"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "f68rqWFNXi9n",
        "outputId": "4369e00f-1122-4633-f740-2fb8f7e66c26"
      },
      "source": [
        "# Check the distribution of our sequences at a character-level\n",
        "plt.hist(char_length,bins=20);"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nWtwTnjYvhl",
        "outputId": "f90dc8c3-f81d-4163-be1a-3be613a6fc17"
      },
      "source": [
        "# What lenght of character covers 95% of sequences in character-level sequences\n",
        "output_seq_char_len = int(np.percentile(char_length,95))\n",
        "output_seq_char_len"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Yvf2VXsNbxNm",
        "outputId": "56450036-709d-4e20-a047-44c3f3e88904"
      },
      "source": [
        "# Get all keyboard characters\n",
        "import string\n",
        "aplhabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "aplhabet"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNmXo4yxdJNa"
      },
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHARS_TOKENS = len(aplhabet) + 2 # add 2 for space and <OOV> token (out of vocab ='[UNK]')\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHARS_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    pad_to_max_tokens=True,\n",
        "                                    name=\"char_vectorizer\")"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfTcGSSPeY6u"
      },
      "source": [
        "# Adapt character vectorizer to training character\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSLLOZAFeg7-",
        "outputId": "b22f799f-dfe6-4e25-fe26-598949c485b4"
      },
      "source": [
        "# Check character vocab stats\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 Most Common Characters: {char_vocab[:5]}\")\n",
        "print(f\"5 Most Least Common Characters: {char_vocab[-5:]}\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 Most Common Characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 Most Least Common Characters: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c0FbChjftkC",
        "outputId": "17f6dc67-c508-490b-9ca4-0c96147db538"
      },
      "source": [
        "# Test our character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n {random_train_chars}\")\n",
        "print(f\"\\nLength of random_train_chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized text:\\n {vectorized_chars}\")\n",
        "print(f\"\\nShape of Vectorized text: {vectorized_chars.shape}\")"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " d a t a   f r o m   a l l   s i t e s   w i l l   b e   m e r g e d   i n   o r d e r   t o   c o m p a r e   p r e v a l e n c e   a n d   a s s o c i a t i o n s   a c r o s s   s i t e s   o n   c o r e   v a r i a b l e s   .\n",
            "\n",
            "Length of random_train_chars: 96\n",
            "\n",
            "Vectorized text:\n",
            " [[10  5  3  5 17  8  7 15  5 12 12  9  4  3  2  9 20  4 12 12 22  2 15  2\n",
            "   8 18  2 10  4  6  7  8 10  2  8  3  7 11  7 15 14  5  8  2 14  8  2 21\n",
            "   5 12  2  6 11  2  5  6 10  5  9  9  7 11  4  5  3  4  7  6  9  5 11  8\n",
            "   7  9  9  9  4  3  2  9  7  6 11  7  8  2 21  5  8  4  5 22 12  2  9  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Shape of Vectorized text: (1, 290)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJcHY9cAgb0X"
      },
      "source": [
        "## Character level embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbiVqF1_khXf"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "char_embed = layers.Embedding(input_dim=len(char_vocab), # number of different characters \n",
        "                              output_dim=25, # size of the char embedding in the paper\n",
        "                              mask_zero=True,\n",
        "                              name=\"char_embedding\")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkozGTbvlTJm",
        "outputId": "73e0b3b4-f541-4c6b-a000-cf19527c6cf7"
      },
      "source": [
        "# Test our character embedding layer\n",
        "print(f\"Charified text:\\n {random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization & embedding):\\n {char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " d a t a   f r o m   a l l   s i t e s   w i l l   b e   m e r g e d   i n   o r d e r   t o   c o m p a r e   p r e v a l e n c e   a n d   a s s o c i a t i o n s   a c r o s s   s i t e s   o n   c o r e   v a r i a b l e s   .\n",
            "\n",
            "Embedded chars (after vectorization & embedding):\n",
            " [[[-0.02154626 -0.03069183 -0.03996533 ...  0.04641395 -0.00824221\n",
            "    0.02120986]\n",
            "  [ 0.04155708  0.03157321 -0.03080451 ... -0.03304116 -0.01054901\n",
            "   -0.01766057]\n",
            "  [-0.00667077  0.03788072 -0.02249831 ...  0.01784178 -0.04753004\n",
            "    0.01548048]\n",
            "  ...\n",
            "  [-0.04936956 -0.03845235 -0.01215938 ...  0.00391593  0.0005927\n",
            "    0.04139607]\n",
            "  [-0.04936956 -0.03845235 -0.01215938 ...  0.00391593  0.0005927\n",
            "    0.04139607]\n",
            "  [-0.04936956 -0.03845235 -0.01215938 ...  0.00391593  0.0005927\n",
            "    0.04139607]]]\n",
            "\n",
            "Character embedding shape: (1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvdqX_S1m3Up"
      },
      "source": [
        "### Building a Conv1D model to fit on character embeddings"
      ]
    }
  ]
}